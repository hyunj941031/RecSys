{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qBY9WErzzXxggssDR6JSg3GLv96dzOvS",
      "authorship_tag": "ABX9TyMW55Ee1STkBSpWGuW/6Bx3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyunj941031/RecSys/blob/main/models/MF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "IEHke91KhV_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-box"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xX4plvyPUAe-",
        "outputId": "ce0611be-e409-4664-b0b5-2308910a3612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-box in /usr/local/lib/python3.8/dist-packages (7.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1JWw0FeTnWR",
        "outputId": "56deac58-bd35-4248-c1b7-49fa6dd860cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.8/dist-packages (2.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (3.19.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorboardX) (23.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CpW4ZeEfCYW"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "from box import Box\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(action='ignore')\n",
        "torch.set_printoptions(sci_mode=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'data_path' : '/content/drive/MyDrive/fashion_campus_dataset',\n",
        "    \n",
        "    'sequence_len' : 50,\n",
        "    'mask_prob' : 0.3, # cloze task\n",
        "    'random_seed' : 123,\n",
        "\n",
        "    'num_layers' : 2, # block 수 (encoder layer 수)\n",
        "    'hidden_units' : 50, # Embedding size\n",
        "    'num_heads' : 2, # Multi-head layer 수 (병렬처리), hidden_units를 나눴을 때 나누어 떨어지게게\n",
        "    'dropout' : 0.15, # dropout의 비율\n",
        "\n",
        "    'epoch' : 5,\n",
        "    'patience' : 5,\n",
        "    'batch_size' : 256,\n",
        "    'lr' : 0.001,\n",
        "\n",
        "    'num_epochs' : 10,\n",
        "    'num_workers' : 4,\n",
        "    'val_data' : 3,\n",
        "    'delete_data' : True,\n",
        "    'sampling' : True,\n",
        "    'sampling_frac' : 0.3,\n",
        "}\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "config = Box(config)"
      ],
      "metadata": {
        "id": "Tey380DAMK7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MakeSequenceDataSet():\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.df = pd.read_csv(os.path.join(self.config.data_path, 'user_item.csv'), index_col=0)\n",
        "        if config['delete_data']:\n",
        "            self.df = self.delete_ones()\n",
        "        if config['sampling']:\n",
        "            self.df = self.sampling_users()\n",
        "\n",
        "        self.item_encoder, self.item_decoder = self.generate_encoder_decoder('itemId')\n",
        "        self.user_encoder, self.user_decoder = self.generate_encoder_decoder('userId')\n",
        "        self.num_item, self.num_user = len(self.item_encoder), len(self.user_encoder)\n",
        "\n",
        "        self.df['item_idx'] = self.df['itemId'].apply(lambda x : self.item_encoder[x] + 1)\n",
        "        self.df['user_idx'] = self.df['userId'].apply(lambda x : self.user_encoder[x])\n",
        "        self.df = self.df.sort_values(['user_idx', 'timestamp'])\n",
        "        self.user_train, self.user_valid = self.split_sequence_data()\n",
        "\n",
        "\n",
        "    def delete_ones(self):\n",
        "        a = self.df.groupby('userId')['itemId'].size()\n",
        "        for i in a.index:\n",
        "            if a[i] <= config['val_data']:\n",
        "                del(a[i])\n",
        "        df_ = self.df.copy()\n",
        "        df_ = df_[df_['userId'].isin(a.index)]\n",
        "                \n",
        "        return df_\n",
        "\n",
        "\n",
        "    def sampling_users(self):\n",
        "        a = self.df.groupby('userId')['userId'].mean().sample(frac=config['sampling_frac'], random_state=config['random_seed'])\n",
        "        df_ = self.df.copy()\n",
        "        df_ = df_[df_['userId'].isin(a.index)]\n",
        "        return df_\n",
        "\n",
        "\n",
        "    def generate_encoder_decoder(self, col:str) -> dict:\n",
        "                '''\n",
        "        encoder, decoder 생성\n",
        "\n",
        "        Args:\n",
        "            col (str): 생성할 columns 명\n",
        "        Return:\n",
        "            dict: 생성된 user encoder, decoder\n",
        "        '''\n",
        "        encoder = {}\n",
        "        decoder = {}\n",
        "        ids = self.df[col].unique()\n",
        "\n",
        "        for idx, _id in enumerate(ids):\n",
        "            encoder[_id] = idx\n",
        "            decoder[idx] = _id\n",
        "\n",
        "        return encoder, decoder\n",
        "\n",
        "\n",
        "    def split_sequence_data(self) -> dict:\n",
        "        users = defaultdict(list)\n",
        "        user_train = {}\n",
        "        user_valid = {}\n",
        "        group_df = self.df.groupby('user_idx')\n",
        "        for user, item in group_df:\n",
        "            users[user].extend(item['item_idx'].tolist())\n",
        "\n",
        "        for user in users:\n",
        "            user_train[user] = users[user][:-config['val_data']]\n",
        "            user_valid[user] = users[user][-config['val_data']:] # 마지막 아이템 예측\n",
        "\n",
        "        return user_train, user_valid\n",
        "\n",
        "\n",
        "    def get_train_valid_data(self):\n",
        "        return self.user_train, self.user_valid"
      ],
      "metadata": {
        "id": "n85w6_OFDuxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NCFData(data.Dataset):\n",
        "    def __init__(self, features, num_item, train_mat=None, num_ng=0, is_training=None):\n",
        "        super(NCFData, self).__init__()\n",
        "        \"\"\" Note that the labels are only useful when training, we thus \n",
        "\t\t\tadd them in the ng_sample() function.\n",
        "\t\t\"\"\"\n",
        "        self.features_ps = features\n",
        "        self.num_item = num_item\n",
        "        self.train_mat = train_mat\n",
        "        self.num_ng = num_ng\n",
        "        self.is_training = is_training\n",
        "        self.labels = [0] * len(features)\n",
        "\n",
        "    def set_ng_sample(self):\n",
        "        assert self.is_training, \"no need to sampling when testing\"\n",
        "\n",
        "        # negative sample 더하기\n",
        "        self.features_ng = []\n",
        "        for x in self.features_ps:\n",
        "            # user\n",
        "            u = x[0]\n",
        "            for _ in range(self.num_ng):\n",
        "                j = np.random.randint(self.num_item)\n",
        "                # train set에 있는 경우 다시 뽑기\n",
        "                while (u, j) in self.train_mat:\n",
        "                    j = np.random.randint(self.num_item)\n",
        "                self.features_ng.append([u, j])\n",
        "\n",
        "        labels_ps = [1] * len(self.features_ps)\n",
        "        labels_ng = [0] * len(self.features_ng)\n",
        "\n",
        "        self.features_fill = self.features_ps + self.features_ng\n",
        "        self.labels_fill = labels_ps + labels_ng\n",
        "\n",
        "    def __len__(self):\n",
        "        return (self.num_ng + 1) * len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = self.features_fill if self.is_training else self.features_ps\n",
        "        labels = self.labels_fill if self.is_training else self.labels\n",
        "\n",
        "        user = features[idx][0]\n",
        "        item = features[idx][1]\n",
        "        label = labels[idx]\n",
        "        return user, item, label"
      ],
      "metadata": {
        "id": "1QgtmdG41UdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(train_data, test_data, num_item, train_mat):\n",
        "\n",
        "    # construct the train and test datasets\n",
        "    # args = (features, num_item, train_mat=None, num_ng=0, is_training=None)\n",
        "    train_dataset = NCFData(train_data, num_item, train_mat, args[\"num_ng\"], True)\n",
        "    test_dataset = NCFData(test_data, num_item, train_mat, 0, False)\n",
        "    train_loader = data.DataLoader(\n",
        "        train_dataset, batch_size=args[\"batch_size\"], shuffle=True, num_workers=4\n",
        "    )\n",
        "    test_loader = data.DataLoader(\n",
        "        test_dataset, batch_size=args[\"test_num_ng\"] + 1, shuffle=False, num_workers=0\n",
        "    )\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "train_loader, test_loader = prepare_data(train_data, test_data, num_item, train_mat)"
      ],
      "metadata": {
        "id": "A7fZa1cmF-vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MF(nn.Module):\n",
        "    def __init__(self, num_user, num_item, num_factor):\n",
        "        super(MF, self).__init__()\n",
        "        self.num_factor = num_factor\n",
        "\n",
        "        self.embed_user = nn.Embedding(num_user, num_factor)\n",
        "        self.embed_item = nn.Embedding(num_item, num_factor)\n",
        "        predict_size = num_factor\n",
        "        self.predict_layer = torch.ones(predict_size, 1) # .cuda()\n",
        "        self._init_weight_()\n",
        "\n",
        "    def _init_weight_(self):\n",
        "        # weight 초기화\n",
        "        nn.init.normal_(self.embed_user.weight, std=0.01)\n",
        "        nn.init.normal_(self.embed_item.weight, std=0.01)\n",
        "\n",
        "        # bias 초기화\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, user, item):\n",
        "        embed_user = self.embed_user(user)\n",
        "        embed_item = self.embed_item(item)\n",
        "        output_GMF = embed_user * embed_item\n",
        "        prediction = torch.matmul(output_GMF, self.predict_layer)\n",
        "        return prediction.view(-1)"
      ],
      "metadata": {
        "id": "qzMTr8rXEMHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(num_user, num_item, args):\n",
        "    model = MF(num_user, num_item, args[\"num_factor\"])\n",
        "    # model.cuda()\n",
        "    loss_function = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args[\"lr\"])\n",
        "    return model, loss_function, optimizer\n",
        "\n",
        "model, loss_function, optimizer = create_model(num_user, num_item, args)"
      ],
      "metadata": {
        "id": "a9gOxuStDx3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hit(gt_item, pred_items):\n",
        "    if gt_item in pred_items:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "\n",
        "def ndcg(gt_item, pred_items):\n",
        "    if gt_item in pred_items:\n",
        "        index = pred_items.index(gt_item)\n",
        "        return np.reciprocal(np.log2(index + 2))\n",
        "    return 0\n",
        "\n",
        "\n",
        "def metrics(model, test_loader, top_k):\n",
        "    HR, NDCG = [], []\n",
        "\n",
        "    for user, item, _ in test_loader:\n",
        "        user = user # .cuda()\n",
        "        item = item # .cuda()\n",
        "\n",
        "        predictions = model(user, item)\n",
        "        # 가장 높은 top_k개 선택\n",
        "        _, indices = torch.topk(predictions, top_k)\n",
        "        # 해당 상품 index 선택\n",
        "        recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
        "        # 정답값 선택\n",
        "        gt_item = item[0].item()\n",
        "        HR.append(hit(gt_item, recommends))\n",
        "        NDCG.append(ndcg(gt_item, recommends))\n",
        "\n",
        "    return np.mean(HR), np.mean(NDCG)"
      ],
      "metadata": {
        "id": "hWNdVVIEL8T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuMF:\n",
        "    def __init__(self, user_num, item_num, latent_features=8):\n",
        "\n",
        "        # Input\n",
        "        user = Input(shape=(1,), dtype='int32')\n",
        "        item = Input(shape=(1,), dtype='int32')\n",
        "\n",
        "        # GMF\n",
        "        # User embedding for GMF\n",
        "        gmf_user_embedding = Embedding(user_num, latent_features, input_length=user.shape[1])(user)\n",
        "        gmf_user_embedding = Flatten()(gmf_user_embedding)\n",
        "        # Item embedding for GMF\n",
        "        gmf_item_embedding = Embedding(item_num, latent_features, input_length=item.shape[1])(item)\n",
        "        gmf_item_embedding = Flatten()(gmf_item_embedding)\n",
        "\n",
        "\n",
        "        # MLP\n",
        "        # User embedding for MLP\n",
        "        mlp_user_embedding = Embedding(user_num, 32, input_length=user.shape[1])(user)\n",
        "        mlp_user_embedding = Flatten()(mlp_user_embedding)\n",
        "        # Item embedding for MLP\n",
        "        mlp_item_embedding = Embedding(item_num, 32, input_length=item.shape[1])(item)\n",
        "        mlp_item_embedding = Flatten()(mlp_item_embedding)\n",
        "\n",
        "\n",
        "        # GMF layers\n",
        "        gmf_mul =  Multiply()([gmf_user_embedding, gmf_item_embedding])\n",
        "\n",
        "\n",
        "        # MLP layers\n",
        "        mlp_concat = Concatenate()([mlp_user_embedding, mlp_item_embedding])\n",
        "        mlp_dropout = Dropout(0.2)(mlp_concat)\n",
        "        # Layer1\n",
        "        mlp_layer_1 = Dense(units=64, activation='relu', name='mlp_layer1')(mlp_dropout)  # (64,1)\n",
        "        mlp_dropout1 = Dropout(rate=0.2, name='dropout1')(mlp_layer_1)                    # (64,1)\n",
        "        mlp_batch_norm1 = BatchNormalization(name='batch_norm1')(mlp_dropout1)            # (64,1)\n",
        "        # Layer2\n",
        "        mlp_layer_2 = Dense(units=32, activation='relu', name='mlp_layer2')(mlp_batch_norm1)  # (32,1)\n",
        "        mlp_dropout2 = Dropout(rate=0.2, name='dropout2')(mlp_layer_2)                        # (32,1)\n",
        "        mlp_batch_norm2 = BatchNormalization(name='batch_norm2')(mlp_dropout2)                # (32,1)\n",
        "        # Layer3\n",
        "        mlp_layer_3 = Dense(units=16, activation='relu', name='mlp_layer3')(mlp_batch_norm2)  # (16,1)\n",
        "        # Layer4\n",
        "        mlp_layer_4 = Dense(units=8, activation='relu', name='mlp_layer4')(mlp_layer_3)       # (8,1)\n",
        "        \n",
        "        \n",
        "        # merge GMF + MLP\n",
        "        merged_vector = tf.keras.layers.concatenate([gmf_mul, mlp_layer_4])\n",
        "\n",
        "        # Output layer\n",
        "        output_layer = Dense(1, kernel_initializer='lecun_uniform', name='output_layer')(merged_vector) # 1,1 / h(8,1)초기화\n",
        "\n",
        "        # Model\n",
        "        self.model = Model([user, item], output_layer)\n",
        "        self.model.compile(optimizer= 'adam', loss= 'binary_crossentropy')\n",
        "\n",
        "    def get_model(self):\n",
        "        model = self.model\n",
        "        return model\n"
      ],
      "metadata": {
        "id": "wafELJ81Jd9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_sequence_dataset = MakeSequenceDataSet(config=config)\n",
        "user_train, user_valid = make_sequence_dataset.get_train_valid_data()"
      ],
      "metadata": {
        "id": "gMnnCmReIkl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = make_sequence_dataset.df\n",
        "num_user = df['userId'].nunique()\n",
        "num_item = df['itemId'].nunique()\n",
        "\n",
        "sparsity = 1 - len(df) / (num_user * num_item)\n",
        "\n",
        "print(f'전체 User 수: {num_user}')\n",
        "print(f'전체 Item 수: {num_item}')\n",
        "print(f'행렬의 희소성: {sparsity:.4f}')"
      ],
      "metadata": {
        "id": "e0bdcXcWuU4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_mat = sp.dok_matrix((num_user, num_item), dtype=np.float32)\n",
        "train_data = []\n",
        "\n",
        "for i in range(len(train_df)):\n",
        "    for j in range(len(train_df[i])):\n",
        "        train_mat[i, train_df[i][j]] = 1.0\n",
        "        train_data.append([i,train_df[i][j]])"
      ],
      "metadata": {
        "id": "bhozSChII9cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "\n",
        "for i in range(len(val_df)):\n",
        "    for j in range(len(val_df[i])):\n",
        "        test_data.append([i,val_df[i][j]])"
      ],
      "metadata": {
        "id": "ptIDP6-9kaow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count, best_hr = 0, 0\n",
        "writer = SummaryWriter()  # for visualization\n",
        "# 모델 파라미터 출력\n",
        "for epoch in range(args[\"epochs\"]):\n",
        "    model.train()  # Enable dropout (if have).\n",
        "\n",
        "    start_time = time.time()\n",
        "    train_loader.dataset.set_ng_sample()\n",
        "\n",
        "    for user, item, label in train_loader:\n",
        "        user = user # .cuda()\n",
        "        item = item # .cuda()\n",
        "        label = label.float() # .cuda()\n",
        "\n",
        "        # gradient 초기화\n",
        "        model.zero_grad()\n",
        "        prediction = model(user, item)\n",
        "        loss = loss_function(prediction, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        writer.add_scalar(\"data/loss\", loss.item(), count)\n",
        "        count += 1\n",
        "\n",
        "    model.eval()\n",
        "    HR, NDCG = metrics(model, test_loader, args[\"top_k\"])\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(\n",
        "        \"The time elapse of epoch {:03d}\".format(epoch + 1)\n",
        "        + \" is: \"\n",
        "        + time.strftime(\"%H: %M: %S\", time.gmtime(elapsed_time))\n",
        "    )\n",
        "    print(\"HR: {:.3f}\\tNDCG: {:.3f}\".format(np.mean(HR), np.mean(NDCG)))\n",
        "\n",
        "    if HR > best_hr:\n",
        "        best_hr, best_ndcg, best_epoch = HR, NDCG, epoch\n",
        "        if args[\"out\"]:\n",
        "            if not os.path.exists(config[\"model_path\"]):\n",
        "                os.mkdir(config[\"model_path\"])\n",
        "            torch.save(\n",
        "                model, \"{}{}.pth\".format(config[\"model_path\"], config[\"model\"])\n",
        "            )\n",
        "\n",
        "print(\n",
        "    \"End. Best epoch {:03d}: HR = {:.3f}, NDCG = {:.3f}\".format(\n",
        "        best_epoch, best_hr, best_ndcg\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT7TfdzXTXDm",
        "outputId": "b4cc0eb2-ae71-4ba2-f5f8-2ba76a0a392a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The time elapse of epoch 000 is: 00: 08: 27\n",
            "HR: 0.123\tNDCG: 0.060\n",
            "The time elapse of epoch 001 is: 00: 07: 46\n",
            "HR: 0.135\tNDCG: 0.063\n",
            "The time elapse of epoch 002 is: 00: 08: 31\n",
            "HR: 0.132\tNDCG: 0.067\n",
            "The time elapse of epoch 003 is: 00: 08: 02\n",
            "HR: 0.144\tNDCG: 0.066\n",
            "The time elapse of epoch 004 is: 00: 09: 12\n",
            "HR: 0.139\tNDCG: 0.067\n",
            "The time elapse of epoch 005 is: 00: 08: 29\n",
            "HR: 0.137\tNDCG: 0.067\n",
            "The time elapse of epoch 006 is: 00: 08: 53\n",
            "HR: 0.116\tNDCG: 0.063\n",
            "The time elapse of epoch 007 is: 00: 08: 42\n",
            "HR: 0.123\tNDCG: 0.065\n",
            "The time elapse of epoch 008 is: 00: 08: 53\n",
            "HR: 0.113\tNDCG: 0.063\n",
            "The time elapse of epoch 009 is: 00: 08: 48\n",
            "HR: 0.106\tNDCG: 0.058\n",
            "End. Best epoch 003: HR = 0.144, NDCG = 0.066\n"
          ]
        }
      ]
    }
  ]
}